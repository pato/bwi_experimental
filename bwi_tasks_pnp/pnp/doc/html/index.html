<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Petri Net Plans: Petri Net Plans</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />



</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">Petri Net Plans
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">Petri Net Plans </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The Petri Net Plan (PNP) formalism allows for high level description of complex action interactions. Such interactions are necessary in programming cognitive agents with real-time requirements, like mobile robots or video game AIs. PNPs are inspired to languages for reasoning about actions. Nonetheless, they are more expressive than most of them, offering a full fledged set of operators for dealing with non-instantaneous actions, sensing actions, action failures, concurrent actions and cooperation in a multi-agent context.</p>
<p>For an introduction to PNP please refer to <a href="http://pnp.dis.uniroma1.it">http://pnp.dis.uniroma1.it</a></p>
<h2><a class="anchor" id="who"></a>
Authors and Maintainers</h2>
<p>PNP has been initially developed by Vittorio A. Ziparo ( <a href="http://www.dis.uniroma1.it/~ziparo/">http://www.dis.uniroma1.it/~ziparo/</a> )</p>
<p>It has then been improved and maintained for a while by Daniele Calisi ( <a href="http://www.dis.uniroma1.it/~calisi/">http://www.dis.uniroma1.it/~calisi/</a> )</p>
<p>It is currently in the clutches of Matteo Leonetti ( <a href="http://www.dis.uniroma1.it/~leonetti/">http://www.dis.uniroma1.it/~leonetti/</a> ) who has also developed the learning part. Please report to him any error in this documentation.</p>
<h2><a class="anchor" id="usage"></a>
General Usage</h2>
<p>You want to follow, more or less, this list:</p>
<ol type="1">
<li>Write a plan and save it in the format you prefer. We suggest the Petri Net Markup Language ( <a href="http://www.informatik.hu-berlin.de/top/pnml/">http://www.informatik.hu-berlin.de/top/pnml/</a> )because we developed a plan loader for it. Otherwise you would have to implement one yourself. Our favourite tools to do so are Jarp ( <a href="http://jarp.sourceforge.net/">http://jarp.sourceforge.net/</a> ) and Pipe ( <a href="http://pipe2.sourceforge.net/">http://pipe2.sourceforge.net/</a> ).</li>
<li>At this point you should have clarified to yourself what actions you need. Implement those actions sub-classing for each of them <a class="el" href="class_petri_net_plans_1_1_pnp_action.html" title="Base class for all actions.">PetriNetPlans::PnpAction</a> and overriding the methods you want (typically among <a class="el" href="class_petri_net_plans_1_1_pnp_action.html#af0a829b311d2c758678c5bda6b5b832d" title="Starts the execution.">PetriNetPlans::PnpAction::start()</a>, <a class="el" href="class_petri_net_plans_1_1_pnp_action.html#af62b70aa7e8f1c872c84f719feda44ab" title="Execute a step of a time extended executable.">PetriNetPlans::PnpAction::executeStep()</a>, <a class="el" href="class_petri_net_plans_1_1_pnp_action.html#a127e8291649259f44553f38f0b722358" title="Terminates the execution.">PetriNetPlans::PnpAction::end()</a>) Pay attention to the termination condition, if you want it to be internal (triggered by the action rather than the plan) you must also override <a class="el" href="class_petri_net_plans_1_1_pnp_action.html#ac0ecb11d21a50127bec4f243585914bd" title="Returns true iff this executable has internally detected its termination.">PetriNetPlans::PnpAction::finished()</a>.</li>
<li>Make sure you have the interface between the agent and the environment ready. This can be as complicated as a Knowledge Base updated according to the agent perceptions, or as simple as a synthetic representation of the environment itself (e.g. the board in tic-tac-toe).</li>
<li>Subclass <a class="el" href="class_petri_net_plans_1_1_external_condition_checker.html" title="A class to test atomic conditions not related to an action.">PetriNetPlans::ExternalConditionChecker</a> and implement <a class="el" href="class_petri_net_plans_1_1_external_condition_checker.html#ad0139401c1da6c4802ff2fe74f9ccffa" title="tests an external atomic condition">PetriNetPlans::ExternalConditionChecker::evaluateAtomicExternalCondition()</a> to test the conditions you used in the plan(s) on your interface to the environment. This class is the bridge between PNP and the outside world. For each <em>atomic</em> condition (or <em>predicate</em>) it must return whether or not it holds according to the agent's knowledge at the time it is invoked.</li>
<li>Subclass <a class="el" href="class_petri_net_plans_1_1_executable_instantiator.html" title="The interface for classes accountable for the creation of plans and actions.">PetriNetPlans::ExecutableInstantiator</a> and have it create your plans and actions. PNP does not distinguish between them, so they are all returned as <a class="el" href="class_petri_net_plans_1_1_pnp_executable.html" title="The interface for executables (i.e. actions and plans).">PetriNetPlans::PnpExecutable</a> instances. This object must know where the plans are stored and what parameters (if any) provide to the actions. None of these things are enforced by PNP. You can implement this class in many different ways and in complicated systems it might require some ingenuity. In order to load plans from pnml files, you can use <a class="el" href="class_petri_net_plans_1_1_x_m_l_pnp_plan_instantiator.html" title="A xml plan loader for basic PnpPlans.">PetriNetPlans::XMLPnpPlanInstantiator</a>. Create an empty plan and pass it to <a class="el" href="class_petri_net_plans_1_1_x_m_l_pnp_plan_instantiator.html#aaf8d799e4e117248f578ada8dd3f6325" title="Loads the plan from a file.">PetriNetPlans::XMLPnpPlanInstantiator::loadFromPNML()</a>. This object also commonly passes itself to the newly created plan to be its instantiator too.</li>
<li>Finally instantiate <a class="el" href="class_petri_net_plans_1_1_pnp_executer.html" title="The Main class for executing Petri Net Plans.">PetriNetPlans::PnpExecuter</a>, and set the name of the main plan with <a class="el" href="class_petri_net_plans_1_1_pnp_executer.html#a31907ca6ca08b84385ec18c9da9fa0b3" title="Sets the name of the main plan.">PetriNetPlans::PnpExecuter::setMainPlan()</a>. Repeatedly call <a class="el" href="class_petri_net_plans_1_1_pnp_executer.html#a929ef1537a046da5cbe12461bd53932f" title="Executes one step of the main plan and all its sub plans.">PetriNetPlans::PnpExecuter::execMainPlanStep()</a> at the frequency you need (this depends on how often you want your agent to make decisions, that usually depends on how fast the environment changes).</li>
</ol>
<p>This list is in the order of the dependencies but I suggest to write the plan first and then follow the other steps in reverse order, so that you'll clearly see when and where you need every component before actually implementing it.</p>
<h2><a class="anchor" id="learning"></a>
PNP and Reinforcement Learning</h2>
<p>A tutorial about learning in PNP is available at <a href="http://www.dis.uniroma1.it/~leonetti/index.php?option=com_content&task=view&id=56&Itemid=54">http://www.dis.uniroma1.it/~leonetti/index.php?option=com_content&amp;task=view&amp;id=56&amp;Itemid=54</a></p>
<p>To use the learning capability you must follow the same steps as for normal PNP with a few differences:</p>
<ul>
<li>Instead of <a class="el" href="class_petri_net_plans_1_1_external_condition_checker.html" title="A class to test atomic conditions not related to an action.">PetriNetPlans::ExternalConditionChecker</a> you must subclass <a class="el" href="classlearnpnp_1_1_reward_collector.html" title="Interface to collect the reward during execution and test external conditions.">learnpnp::RewardCollector</a>. It IS-A ExternalConditionChecker but in addition has a function to communicate to PNP the reward obtained between two subsequent calls of <a class="el" href="classlearnpnp_1_1_reward_collector.html#af6ec76921e03e903ae4b11aff2b17421" title="returns the reward accumulated since the last time this method was invoked">learnpnp::RewardCollector::reward()</a>. Since both accumulating the reward and testing conditions need access to the agent's knowledge about the environment they are implemented by the same component.</li>
<li>The executable instantiator (the subclass of <a class="el" href="class_petri_net_plans_1_1_executable_instantiator.html" title="The interface for classes accountable for the creation of plans and actions.">PetriNetPlans::ExecutableInstantiator</a>) must return through the method <a class="el" href="class_petri_net_plans_1_1_executable_instantiator.html#a0f7366d920f2220388cdf0622a948bb4" title="The method to implement to return plans and actions.">PetriNetPlans::ExecutableInstantiator::createExecutable()</a> an instance of <a class="el" href="classlearnpnp_1_1_learn_plan.html" title="A PetriNetPlans::PnpPlan that uses a Reinforcement Learning algorithm to choose among non-determinist...">learnpnp::LearnPlan</a> instead of <a class="el" href="namespace_petri_net_plans.html#a62bdbed25773851b18e0d93474bf9dc8" title="Definition of PnpPlan to simplify the code.">PetriNetPlans::PnpPlan</a>.</li>
<li>When more than one next marking is possible, that is in non-deterministic choice points, the control is taken over by the <a class="el" href="structlearnpnp_1_1_controller.html" title="Controllers make decisions in non-deterministic choice points and take care of learning.">learnpnp::Controller</a> provided to the plan.</li>
</ul>
<h3><a class="anchor" id="controllers"></a>
A word about controllers</h3>
<p>Controllers are in charge of learning and making decisions in non-deterministic choice points. A few default implementations are provided for ease of use. A <a class="el" href="classlearnpnp_1_1_basic_controller.html" title="A simple controller that delegates learning to a Learner and exploration to a ExpPolicy.">learnpnp::BasicController</a> delegates learning to a <a class="el" href="classlearnpnp_1_1_learner.html" title="A generic algorithm based on a value function.">learnpnp::Learner</a>, and to a and to a <a class="el" href="classlearnpnp_1_1_exp_policy.html" title="The interface for exploration policies based on a value function.">learnpnp::ExpPolicy</a>. The former manages the value function and implements an update rule. The latter chooses one of the possible next markings, given their values. Two common choices are <a class="el" href="classlearnpnp_1_1_t_d_lambda.html" title="An on-policy learning algorithm based on TD(lambda)">learnpnp::TDLambda</a> for the learner and <a class="el" href="classlearnpnp_1_1_e_greedy.html" title="Implements an epsilon-greedy exploration strategy.">learnpnp::EGreedy</a> for the exploration policy.</p>
<p>Controllers are available in the directory pnp/learning_plan/algo/ and exploration strategies in pnp/learning_plan/exp/. Both have generic interfaces that can be extended to implement one's particular needs.</p>
<p>Worth mentioning is also that <a class="el" href="classlearnpnp_1_1_basic_controller.html" title="A simple controller that delegates learning to a Learner and exploration to a ExpPolicy.">learnpnp::BasicController</a> is a <a class="el" href="classlearnpnp_1_1_logging_controller.html" title="A Controller that can log markings&#39; values at the end of each episode.">learnpnp::LoggingController</a>, which means it is also able to log onto a file the values of the specified markings at the end of each episode. This allows to monitor how the learning is going at specific choice points. </p>
</div></div><!-- contents -->


<hr class="footer"/><address class="footer"><small>
Generated on Thu Oct 9 2014 02:16:36 for Petri Net Plans by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.6.1
</small></address>

</body>
</html>
